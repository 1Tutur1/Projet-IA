## Afficher les arbres en fonction de leur hauteur sur la carte ##
stquentin_img = mpimg.imread('C:/Users/apeta/PycharmProjects/projetIA3A/stquentin.PNG')

# Tracer le scatter plot
bdd.plot(kind="scatter", x="longitude", y="latitude", alpha=0.4, label="arbres",
         c="haut_tot", colormap="gist_rainbow", colorbar=True, sharex=False, figsize=(10,7),s=10)
# Ajouter l'image avec plt.imshow
plt.imshow(stquentin_img, extent=(3.24, 3.33, 49.825, 49.873), alpha=0.5)

# Afficher la légende et le graphique
plt.legend()
plt.show()

## Fin affichage sur la carte


--------PA-----------

bdd = pd.read_csv("C:/Users/pierr/PycharmProjects/Projet_IA/Data_Arbre.csv",delimiter=";")

def cluster_hauteur(nb_cluster):
    bdd.drop(columns=["clc_quartier","clc_secteur","remarquable","feuillage","villeca","fk_nomtech","clc_nbr_diag","fk_prec_estim","age_estim","fk_revetement","fk_situation","fk_pied","fk_port","fk_stadedev","fk_arb_etat","tronc_diam","haut_tronc"], inplace=True)
    X = bdd[["haut_tot"]]

    obj_kmeans = KMeans(n_clusters=nb_cluster, random_state=42)
    obj_kmeans.fit(X)
    indices_cluster = obj_kmeans.predict(X)
    return indices_cluster


def visualisation_cluster_hauteur(nb_cluster):
    indices_cluster = cluster_hauteur(nb_cluster)
    bdd["cluster"] = indices_cluster
    stquentin = mpimg.imread("C:/Users/pierr/PycharmProjects/Projet_IA/stquentin.PNG")
    bdd.plot(kind="scatter", x="longitude", y="latitude", label="arbres",c="cluster",cmap="rainbow", figsize=(10,7),s=10,colorbar=False)
    plt.imshow(stquentin, extent=(3.24, 3.33, 49.825, 49.873))

    plt.show()

visualisation_cluster_hauteur(5)
-----------------------------



centroids = obj_kmeans.cluster_centers_
print(centroids)

## Convertir les données non-numériques en numérique ##
colonnes_a_convertir = ['fk_arb_etat','fk_stadedev']
encoder = OrdinalEncoder()
bdd[colonnes_a_convertir] = encoder.fit_transform(bdd[colonnes_a_convertir])

## Fin conversion ##
#fonctionnalité 2
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split, GridSearchCV

# Sélection des caractéristiques et de la cible
X = bdd[["haut_tot", "longitude", "latitude","tronc_diam"]]
y = bdd["age_estim"]

# Séparation en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalisation des données
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Initialisation et entraînement du modèle Random Forest
model = RandomForestRegressor(random_state=42)
model.fit(X_train, y_train)

# Prédiction sur l'ensemble de test
y_pred = model.predict(X_test)

# Calcul des métriques
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R² Score: {r2}")


# Définition de la grille des hyperparamètres à tester
param_grid = {
    'fit_intercept': [True, False],
'n_jobs': [None, 1, 2, 4],
    'copy_X': [True, False]
}

# Initialisation du GridSearchCV
grid_search = GridSearchCV(estimator=model,
                           param_grid=param_grid,
                           scoring='neg_mean_squared_error',  # Métrique à optimiser (ici MSE)
                           cv=5,  # Nombre de folds pour la validation croisée
                           verbose=1,  # Affichage des détails
                           n_jobs=-1  # Utilisation de tous les cœurs du CPU
                          )

# Exécution de la recherche sur la grille avec les données d'entraînement
grid_search.fit(X_train, y_train)

# Affichage des meilleurs paramètres et du meilleur score
print(f"Meilleurs paramètres : {grid_search.best_params_}")
print(f"Meilleur score : {grid_search.best_score_}")

# Utilisation du meilleur modèle trouvé
best_model = grid_search.best_estimator_

# Prédiction avec le meilleur modèle sur l'ensemble de test
y_pred_best = best_model.predict(X_test)

# Évaluation du meilleur modèle
mse_best = mean_squared_error(y_test, y_pred_best)
r2_best = r2_score(y_test, y_pred_best)

print(f"Mean Squared Error (best model): {mse_best}")
print(f"R² Score (best model): {r2_best}")


