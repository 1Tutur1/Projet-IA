import pandas as pd
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
from sklearn.preprocessing import OrdinalEncoder
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score
import sys

# Charger le fichier CSV
bdd = pd.read_csv('C:/Users/apeta/PycharmProjects/projetIA3A/Data_Arbre.csv')

# on fixe le nombre de clusters maximum, si l'on change sa valeur cela changera le graphique des métriques
NB_CLUSTERS_MAX = 10


def cluster_hauteur(nb_cluster):
    bdd.drop(columns=["clc_quartier","clc_secteur","remarquable","feuillage","villeca","fk_nomtech","clc_nbr_diag","fk_prec_estim","age_estim","fk_revetement","fk_situation","fk_pied","fk_port","fk_stadedev","fk_arb_etat","tronc_diam","haut_tronc"], inplace=True)
    X = bdd[["haut_tot"]]

    obj_kmeans = KMeans(n_clusters=nb_cluster, random_state=42)
    obj_kmeans.fit(X)
    indices_cluster = obj_kmeans.predict(X)

    #crée le fichier contenant les centroides nécessaires pour les scripts de la partie 3
    centroids = obj_kmeans.cluster_centers_
    fichier_centroide = open(file="centroides.txt", mode='w')
    for centroide in centroids:
        fichier_centroide.write(str(centroide[0])+'\n')
    fichier_centroide.close()

    return indices_cluster


def calcul_silhouette(train_set, obj_labels):
    return silhouette_score(train_set, obj_labels)


def calcul_calinski_harabasz(train_set, obj_labels):
    return calinski_harabasz_score(train_set, obj_labels)


def calcul_davies_bouldin(train_set, obj_labels):
    return davies_bouldin_score(train_set, obj_labels)


# Initialiser des listes pour stocker les valeurs des indices
silhouette_scores = []
calinski_harabasz_scores = []
davies_bouldin_scores = []

# Initialiser la base d'apprentissage
X = bdd[["haut_tot", "longitude", "latitude"]]

# Boucler sur le nombre de clusters afin d'afficher les métriques selon ce nombre
for k in range(2, NB_CLUSTERS_MAX + 1):
    obj_kmeans = KMeans(n_clusters=k, random_state=42)
    obj_kmeans.fit(X)
    labels = obj_kmeans.labels_

    silhouette_scores.append(calcul_silhouette(X, labels))
    calinski_harabasz_scores.append(calcul_calinski_harabasz(X, labels))
    davies_bouldin_scores.append(calcul_davies_bouldin(X, labels))

print(silhouette_scores)
print(calinski_harabasz_scores)
print(davies_bouldin_scores)


# Afficher les valeurs sur un graphique
plt.figure(figsize=(12, 6))


def visualisation_metrique(nom_metrique, liste_scores_metriques, nb_clusters_max, i, j, k):
    plt.subplot(i, j, k)
    plt.plot(range(2, nb_clusters_max + 1), liste_scores_metriques, marker='o')
    plt.xlabel('Nombre de clusters')
    plt.ylabel(f'{nom_metrique} value')
    plt.title(nom_metrique)


visualisation_metrique("Silhouette Coefficient", silhouette_scores, NB_CLUSTERS_MAX, 1, 3, 1)
visualisation_metrique("Calinski-Harabasz Index", calinski_harabasz_scores, NB_CLUSTERS_MAX, 1, 3, 2)
visualisation_metrique("Davies-Bouldin Index", davies_bouldin_scores, NB_CLUSTERS_MAX, 1, 3, 3)
plt.tight_layout()
plt.show()


def apprentisage_non_supervise(fichier_centroide,features):
    fichier_centroide = open(file=fichier_centroide, mode='r')
    centroides = fichier_centroide.readlines()
    liste_centroides = []
    for centroide in centroides:
        liste_centroides.append(float(centroide.strip()))
    fichier_centroide.close()
    liste_distance = []
    for centroide in liste_centroides:
        liste_distance.append(abs(float(features)-centroide))
    indice_min = liste_distance.index(min(liste_distance))
    return f"L'arbre appartient au cluster {indice_min+1} dont la haut_tot du centroide vaut {liste_centroides[indice_min]}"


--------Stockage de pa----

def cluster_taille(nb_cluster):

    bdd.drop(columns=["clc_quartier","clc_secteur","feuillage","villeca","fk_nomtech","clc_nbr_diag","fk_prec_estim","fk_revetement","fk_pied","fk_port","fk_stadedev","fk_arb_etat"], inplace=True)

    colonnes_a_convertir = ['remarquable', 'fk_situation']
    encoder = OrdinalEncoder()
    bdd[colonnes_a_convertir] = encoder.fit_transform(bdd[colonnes_a_convertir])
    X = bdd[["haut_tot", "haut_tronc","tronc_diam", "fk_situation","age_estim", "remarquable"]]

    obj_kmeans = KMeans(n_clusters=nb_cluster, random_state=42)
    obj_kmeans.fit(X)
    indices_cluster = obj_kmeans.predict(X)

    #crée le fichier contenant les centroides nécessaires pour les scripts de la partie 3
    centroids = obj_kmeans.cluster_centers_
    fichier_centroide = open(file="centroides.csv", mode='w',newline='')
    ecriture = csv.writer(fichier_centroide, delimiter=';')
    ecriture.writerow(["haut_tot", "haut_tronc", "tronc_diam", "fk_situation", "age_estim", "remarquable"])
    for centroide in centroids:
        ecriture.writerow(centroide)
    fichier_centroide.close()
    return indices_cluster

def visualisation_cluster_taille(nb_cluster):
    indices_cluster = cluster_taille(nb_cluster)
    bdd["cluster"] = indices_cluster
    stquentin = mpimg.imread("C:/Users/pierr/PycharmProjects/Projet_IA/stquentin.PNG")
    bdd.plot(kind="scatter", x="longitude", y="latitude",c="cluster",colormap="gist_rainbow", figsize=(10,7),s=10,colorbar=False)
    plt.imshow(stquentin, extent=(3.24, 3.33, 49.825, 49.873))
    plt.xlabel('Longitude')
    plt.ylabel('Latitude')
    plt.show()

visualisation_cluster_taille(3)

def apprentisage_non_supervise(fichier_centroide,features):
    centroides = pd.read_csv(fichier_centroide,delimiter = ";")
    print(centroides)
    liste_distance = []
    for i in range(0,len(centroides)):
        distance = math.sqrt((centroides["haut_tot"][i]-features[0])**2
                             +(centroides["haut_tronc"][i]-features[1])**2
                             +(centroides["tronc_diam"][i]-features[2]) ** 2
                             +(centroides["fk_situation"][i]-features[3]) ** 2
                             +(centroides["age_estim"][i]-features[4]) ** 2
                             +(centroides["remarquable"][i]-features[5]) ** 2)
        liste_distance.append(distance)
    print(liste_distance)
    indice_min = liste_distance.index(min(liste_distance))
    print(f"L'arbre appartient au cluster {indice_min+1}")
    return f"L'arbre appartient au cluster {indice_min+1}"
